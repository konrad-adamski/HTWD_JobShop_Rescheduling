{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Rolling Planning mit Lateness (Tardiness + Earliness)",
   "id": "a099513bae901e7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "max_time = 60*30 # 1/2h",
   "id": "a80878b91fb4719e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import time",
   "id": "ee6829cd3928e04d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ortools.sat.python import cp_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_rows', 20)"
   ],
   "id": "22a48143e608656e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import utils.presenter as show\n",
    "import utils.checker as check\n",
    "\n",
    "import utils.scheduling_solver as ssv\n",
    "import utils.rescheduling_solver_lateness as rssv\n",
    "\n",
    "import utils.rolling_planning.init_jobs_times as rp_init\n",
    "import utils.rolling_planning.procedure as rp_proced\n",
    "import utils.schedule_deadline as deadline_gen\n",
    "\n",
    "from ProductionDaySimulation import ProductionDaySimulation"
   ],
   "id": "ad3edf6cd2b4592e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "start_notebook = time.time()",
   "id": "ba2d173d1558cc9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_schedule_filename(prefix: str = \"\", day: int = 0, data_txt: str = \"schedule\", suffix: str = \"\") -> str:\n",
    "    file_template = \"data/{prefix}_{data}_{day:02d}{suffix}.csv\"\n",
    "    if suffix:\n",
    "        suffix = f\"_{suffix}\"\n",
    "    return file_template.format(prefix=prefix,data=data_txt,day=day, suffix=suffix)"
   ],
   "id": "fa2e68f30bcb29c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generierung des Datensatzes für 10 Tage (Ankunft)",
   "id": "5f0739a5d0449ca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_instance = pd.read_csv(\"data/00_instance.csv\")\n",
    "\n",
    "df_jssp, df_arrivals = rp_init.init_jobs_with_arrivals(df_instance, 10,  u_b_mmax = 0.98)\n",
    "df_jssp"
   ],
   "id": "a7be1eb29adb1aac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Deadlines + Umwandlung in Integer\n",
    "df_times = deadline_gen.get_times_df(df_jssp, df_arrivals, ssv.schedule_fcfs_with_arrivals, target_service=1)\n",
    "df_times[\"Arrival\"] = np.floor(df_times[\"Arrival\"]).astype(int)\n",
    "df_times[\"Deadline\"] = np.ceil(df_times[\"Deadline\"]).astype(int)\n",
    "df_times"
   ],
   "id": "32626a520c17eecb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Params",
   "id": "96873da1f885c48f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# fix\n",
    "day_length = 1440\n",
    "horizon_days = 3"
   ],
   "id": "1f5c3b0fae3c2668"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# init\n",
    "day_numb = 0\n",
    "\n",
    "day_start = 0\n",
    "day_end = 0\n",
    "planning_end = 0"
   ],
   "id": "49acd5e131b7ac3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialisierung (Tag 0)",
   "id": "56387e5362671e62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "day_numb = 0\n",
    "\n",
    "day_start = day_length*day_numb                      # 0\n",
    "day_end = day_start + day_length                     # 1440\n",
    "planning_end =  day_start + horizon_days*day_length  # 4320"
   ],
   "id": "4a1fc54de5564722"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# I)\n",
    "df_jssp_curr, df_times_curr = rp_proced.filter_jobs_by_arrival_window(df_times, df_jssp, day_start, planning_end)\n",
    "df_jssp_curr"
   ],
   "id": "80140aa5229bdcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_times_curr ",
   "id": "b3d4c5521cf04bc8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scheduling",
   "id": "87a8b28acc54666a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "starting_time = time.time()\n",
    "\n",
    "# Scheduling\n",
    "df_plan = ssv.solve_cp_jssp_lateness_by_tardiness_and_earliness(df_jssp_curr, df_times_curr,\n",
    "                                                                w_t = 5,\n",
    "                                                                msg=False, timeLimit=max_time, gapRel= 0.00)\n",
    "df_plan\n",
    "\n",
    "# Informationen\n",
    "ending_time = time.time()\n",
    "solver_duration = ending_time - starting_time\n",
    "print(f\"\\nScheduling-Dauer: {int(solver_duration // 60)} Minuten und {(solver_duration % 60):.2f} Sekunden.\")\n",
    "df_plan"
   ],
   "id": "8b62c63b61d04886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "show.plot_gantt_jobs(df_plan)\n",
    "\n",
    "check.is_machine_conflict_free(df_plan)\n",
    "check.is_operation_sequence_correct(df_plan)\n",
    "check.is_job_timing_correct(df_plan)\n",
    "check.is_start_correct(df_plan)"
   ],
   "id": "ff4b7ab117cfdfb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "show.plot_gantt_machines(df_plan)",
   "id": "bb06a5ad4b9a05f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "last_ops = df_plan.sort_values(['Job', 'Operation']).drop_duplicates('Job', keep='last')\n",
    "show.count_column_grouped(last_ops, \"Lateness\", max_val = 90, steps= 30)"
   ],
   "id": "7a541464d33d3f5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Simulation",
   "id": "b3522247a62f227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "simulation = ProductionDaySimulation(df_plan, vc=0.35)\n",
    "df_execution, df_undone = simulation.run(start_time = day_start, end_time=day_end)"
   ],
   "id": "fcd27c7eaeffa4ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if not df_execution.empty:\n",
    "    show.plot_gantt_machines(df_execution, duration_column=\"Simulated Processing Time\")\n",
    "else:\n",
    "    print(f\"Nothing executed on day {day_numb}\")"
   ],
   "id": "4527cd245b3b84e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_undone",
   "id": "29f2f54cc3d2345c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_plan.to_csv(get_schedule_filename(\"06\", day=day_numb, suffix=\"init\"), index = False)",
   "id": "5e9148c86357c9ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_plan_init = df_plan\n",
    "df_execution_init = df_execution"
   ],
   "id": "a02a70ca9ac0ff52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "-",
   "id": "2a9a005a256ee9dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A) Rolling Planning Simple",
   "id": "9bae3ff51d72f556"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Zielfunktion:**\n",
    "\n",
    "Minimiere die gewichtete Summe aus Tardiness und Earliness der Jobs:\n",
    "\n",
    "\\\\[\n",
    "Z(\\sigma) = \\sum_{j} \\left( w_t \\cdot \\text{Tardiness}_j + w_e \\cdot \\text{Earliness}_j \\right)\n",
    "\\\\]\n",
    "\n",
    "wobei:\n",
    "\n",
    "- \\\\( w_t \\in \\mathbb{N},\\ w_e \\in \\mathbb{N} \\\\): Gewicht für Tardiness und Earliness  \n",
    "- \\\\( \\text{Tardiness}_j = \\max(0, C_j - d_j) \\\\), \\\\( \\text{Earliness}_j = \\max(0, d_j - C_j) \\\\)  \n",
    "    - \\\\( C_j \\\\): Fertigstellungszeitpunkt der letzten Operation von Job \\\\( j \\\\)  \n",
    "    - \\\\( d_j \\\\): Deadline für Job \\\\( j \\\\)\n"
   ],
   "id": "df882077a4c6572d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prefix_name = \"06_simple\"\n",
    "\n",
    "first_start = 1\n",
    "last_planning_start = 7\n",
    "\n",
    "df_plan = df_plan_init\n",
    "df_execution = df_execution_init\n",
    "\n",
    "for day_numb in range(first_start, 2 + 1):\n",
    "    day_start = day_length * day_numb\n",
    "    day_end = day_start + day_length\n",
    "    planning_end = day_start + horizon_days * day_length\n",
    "\n",
    "    # ------------------- I. Ankunfts- und Operationsvorbereitung -------------------\n",
    "    df_jssp_curr, df_times_curr = rp_proced.filter_jobs_by_arrival_window(df_times, df_jssp, day_start, planning_end)\n",
    "    df_jssp_curr = rp_proced.extend_with_undone_operations(df_jssp_curr, df_undone)\n",
    "    df_times_curr = rp_proced.update_times_after_operation_changes(df_times, df_jssp_curr)\n",
    "\n",
    "    # ------------------- II. Relevante laufende Operationen -------------------------\n",
    "    df_execution_important = rp_proced.get_operations_running_into_day(df_execution, day_start)\n",
    "\n",
    "    # ------------------- III. Rescheduling durchführen -------------------------------\n",
    "\n",
    "    starting_time = time.time()\n",
    "    df_plan = rssv.solve_cp_jssp_lateness_by_tardiness_and_earliness_with_fixed_ops(df_jssp_curr, df_times_curr, df_execution_important,\n",
    "                                                                                    w_t = 5, reschedule_start = day_start, \n",
    "                                                                                    msg=False, timeLimit=max_time, gapRel= 0)\n",
    "\n",
    "    \n",
    "    solver_duration = time.time() - starting_time\n",
    "    print(f\"\\n  Scheduling-Dauer: {int(solver_duration // 60)} Minuten und {(solver_duration % 60):.2f} Sekunden.\")\n",
    "\n",
    "    df_plan.to_csv(get_schedule_filename(prefix_name, day=day_numb), index=False)\n",
    "\n",
    "    show.plot_gantt_machines(df_plan, title=f\"Gantt-Diagramm ab Tag {day_numb}\")\n",
    "    check.check_constraints(df_plan)\n",
    "\n",
    "    last_ops = df_plan.sort_values(['Job', 'Operation']).drop_duplicates('Job', keep='last')\n",
    "    print(show.count_column_grouped(last_ops, \"Lateness\", max_val = 180, steps= 60))\n",
    "\n",
    "    # ------------------- IV. Einen Tag simulieren -------------------------------------\n",
    "\n",
    "    simulation = ProductionDaySimulation(df_plan, vc=0.35)\n",
    "    df_execution, df_undone = simulation.run(start_time=day_start, end_time=day_end)\n",
    "    if not df_execution.empty:\n",
    "        show.plot_gantt_machines(df_execution, title=f\"Gantt-Diagramm für Simulationstag {day_numb}\", duration_column=\"Simulated Processing Time\")\n",
    "    else:\n",
    "        print(f\"Nothing executed on day {day_numb}\")"
   ],
   "id": "c5fee6412112ad4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## B) Rolling Planning mit \"Deviation Penalty\"",
   "id": "46ba8dda8830425"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Zielfunktion:**\n",
    "\n",
    "Minimiere die gewichtete Summe aus Tardiness, Earliness und Abweichung vom ursprünglichen Startzeitpunkt (Deviation):\n",
    "\n",
    "\\\\[\n",
    "Z(\\sigma) = r \\cdot \\sum_{j} \\left( w_t \\cdot \\text{Tardiness}_j + w_e \\cdot \\text{Earliness}_j \\right) + (1 - r) \\cdot \\sum_{j,o} \\left| S_{jo} - S_{jo}^{\\text{original}} \\right|\n",
    "\\\\]\n",
    "\n",
    "wobei:\n",
    "\n",
    "- \\\\( r \\in [0,\\ 1] \\\\): Gewichtung zwischen Termintreue und Planstabilität  \n",
    "- \\\\( w_t \\in \\mathbb{N},\\ w_e \\in \\mathbb{N} \\\\): Gewicht für Tardiness und Earliness  \n",
    "- \\\\( \\text{Tardiness}_j = \\max(0, C_j - d_j) \\\\), \\\\( \\text{Earliness}_j = \\max(0, d_j - C_j) \\\\)  \n",
    "    - \\\\( C_j \\\\) ist das Fertigstellungsdatum des letzten Schritts von Job \\\\( j \\\\)  \n",
    "    - \\\\( d_j \\\\) ist die Deadline für Job \\\\( j \\\\)  \n",
    "- \\\\( S_{jo} \\\\) ist der Startzeitpunkt der \\\\( o \\\\)-ten Operation von Job \\\\( j \\\\)  \n",
    "- \\\\( S_{jo}^{\\text{original}} \\\\) ist der ursprünglich geplante Startzeitpunkt\n",
    "\n"
   ],
   "id": "e9dc1fad38de7fa5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ortools.sat.python import cp_model\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def solve_cp_jssp_lateness_by_tardiness_and_earliness_with_devpen(\n",
    "    df_jssp: pd.DataFrame,\n",
    "    df_arrivals_deadlines: pd.DataFrame,\n",
    "    df_executed: pd.DataFrame,\n",
    "    df_original_plan: pd.DataFrame,\n",
    "    w_t: int = 5,\n",
    "    w_e: int = 1,\n",
    "    r: float = 0.5,\n",
    "    reschedule_start: float = 1440.0,\n",
    "    sort_ascending: bool = False,\n",
    "    msg: bool = False,\n",
    "    timeLimit: int = 3600,\n",
    "    gapRel: float = 0.0\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Solves a Job-Shop Scheduling Problem using Constraint Programming with:\n",
    "    - weighted tardiness,\n",
    "    - earliness,\n",
    "    - deviation penalty from a given reference plan (df_original_plan).\n",
    "\n",
    "    Only deviations for operations present in both df_jssp and df_original_plan are considered.\n",
    "\n",
    "    Parameters:\n",
    "        df_jssp: Job-Shop structure with ['Job','Operation','Machine','Processing Time']\n",
    "        df_arrivals_deadlines: Arrival and Deadline info per Job\n",
    "        df_executed: Already executed operations\n",
    "        df_original_plan: Reference plan with original start times\n",
    "        w_t, w_e: Weights for tardiness and earliness\n",
    "        r: Relative weight between lateness and deviation (0–1)\n",
    "        reschedule_start: Planning starts from this time onward\n",
    "        sort_ascending: Sort jobs by deadline ascending (default: False)\n",
    "        msg: Verbose solver output\n",
    "        timeLimit: Max solver time in seconds\n",
    "        gapRel: Relative gap limit\n",
    "\n",
    "    Returns:\n",
    "        df_schedule: A DataFrame with scheduled operations and timing info\n",
    "    \"\"\"\n",
    "\n",
    "    model = cp_model.CpModel()\n",
    "    w_t = int(w_t)\n",
    "    w_e = int(w_e)\n",
    "    r_scaled = int(round(r * 100))  # scaled for integer arithmetic\n",
    "\n",
    "    # === Vorbereitung: Ankunft, Deadline, Jobliste ===\n",
    "    df_arrivals_deadlines = df_arrivals_deadlines.sort_values(\"Deadline\", ascending=sort_ascending).reset_index(drop=True)\n",
    "    arrival = df_arrivals_deadlines.set_index(\"Job\")[\"Arrival\"].to_dict()\n",
    "    deadline = df_arrivals_deadlines.set_index(\"Job\")[\"Deadline\"].to_dict()\n",
    "    jobs = df_arrivals_deadlines[\"Job\"].tolist()\n",
    "\n",
    "    # === Relevante Deviation-Paare bestimmen ===\n",
    "    deviation_relevant_ops = set(\n",
    "        df_jssp[[\"Job\", \"Operation\"]].apply(tuple, axis=1)\n",
    "    ) & set(\n",
    "        df_original_plan[[\"Job\", \"Operation\"]].apply(tuple, axis=1)\n",
    "    )\n",
    "\n",
    "    original_start = {\n",
    "        (row[\"Job\"], row[\"Operation\"]): int(round(row[\"Start\"]))\n",
    "        for _, row in df_original_plan.iterrows()\n",
    "        if (row[\"Job\"], row[\"Operation\"]) in deviation_relevant_ops\n",
    "    }\n",
    "\n",
    "    # === Operationen strukturieren ===\n",
    "    ops_grouped = df_jssp.sort_values([\"Job\", \"Operation\"]).groupby(\"Job\")\n",
    "    all_ops, machines = [], set()\n",
    "    for job in jobs:\n",
    "        seq = []\n",
    "        for _, row in ops_grouped.get_group(job).iterrows():\n",
    "            op_id = int(row[\"Operation\"])\n",
    "            m = str(row[\"Machine\"])\n",
    "            d = int(round(row[\"Processing Time\"]))\n",
    "            seq.append((op_id, m, d))\n",
    "            machines.add(m)\n",
    "        all_ops.append(seq)\n",
    "\n",
    "    # === Planungshorizont abschätzen ===\n",
    "    horizon = int(df_jssp[\"Processing Time\"].sum() + max(deadline.values()))\n",
    "\n",
    "    # === Fixierte Operationen berücksichtigen ===\n",
    "    df_executed_fixed = df_executed[df_executed[\"End\"] >= reschedule_start]\n",
    "    fixed_ops = {\n",
    "        m: list(grp[[\"Start\", \"End\"]].itertuples(index=False, name=None))\n",
    "        for m, grp in df_executed_fixed.groupby(\"Machine\")\n",
    "    }\n",
    "    last_executed_end = df_executed.groupby(\"Job\")[\"End\"].max().to_dict()\n",
    "\n",
    "    # === Variablen definieren ===\n",
    "    starts, ends, intervals = {}, {}, {}\n",
    "    weighted_terms = []\n",
    "    deviation_terms = []\n",
    "\n",
    "    for j, job in enumerate(jobs):\n",
    "        for o, (op_id, m, d) in enumerate(all_ops[j]):\n",
    "            suffix = f\"{j}_{o}\"\n",
    "            start = model.NewIntVar(0, horizon, f\"start_{suffix}\")\n",
    "            end = model.NewIntVar(0, horizon, f\"end_{suffix}\")\n",
    "            interval = model.NewIntervalVar(start, d, end, f\"interval_{suffix}\")\n",
    "            starts[(j, o)] = start\n",
    "            ends[(j, o)] = end\n",
    "            intervals[(j, o)] = (interval, m)\n",
    "\n",
    "    # === Constraints und Zielterme ===\n",
    "    for j, job in enumerate(jobs):\n",
    "        last_op_index = len(all_ops[j]) - 1\n",
    "        job_end = ends[(j, last_op_index)]\n",
    "\n",
    "        # Lateness = End - Deadline\n",
    "        lateness = model.NewIntVar(-horizon, horizon, f\"lateness_{j}\")\n",
    "        model.Add(lateness == job_end - deadline[job])\n",
    "\n",
    "        # Tardiness\n",
    "        tardiness = model.NewIntVar(0, horizon, f\"tardiness_{j}\")\n",
    "        model.AddMaxEquality(tardiness, [lateness, 0])\n",
    "        term_tardiness = model.NewIntVar(0, horizon * w_t, f\"term_tardiness_{j}\")\n",
    "        model.Add(term_tardiness == w_t * tardiness)\n",
    "        weighted_terms.append(term_tardiness)\n",
    "\n",
    "        # Earliness\n",
    "        earliness = model.NewIntVar(0, horizon, f\"earliness_{j}\")\n",
    "        model.AddMaxEquality(earliness, [-lateness, 0])\n",
    "        term_earliness = model.NewIntVar(0, horizon * w_e, f\"term_earliness_{j}\")\n",
    "        model.Add(term_earliness == w_e * earliness)\n",
    "        weighted_terms.append(term_earliness)\n",
    "\n",
    "        # Startzeitbedingungen\n",
    "        model.Add(starts[(j, 0)] >= max(arrival[job], int(reschedule_start)))\n",
    "        if job in last_executed_end:\n",
    "            model.Add(starts[(j, 0)] >= int(math.ceil(last_executed_end[job])))\n",
    "\n",
    "        # Technologische Reihenfolge\n",
    "        for o in range(1, len(all_ops[j])):\n",
    "            model.Add(starts[(j, o)] >= ends[(j, o - 1)])\n",
    "\n",
    "        # Deviation: nur für relevante Ops\n",
    "        for o, (op_id, _, _) in enumerate(all_ops[j]):\n",
    "            key = (job, op_id)\n",
    "            if key in original_start:\n",
    "                dev = model.NewIntVar(0, horizon, f\"dev_{j}_{o}\")\n",
    "                diff = model.NewIntVar(-horizon, horizon, f\"diff_{j}_{o}\")\n",
    "                model.Add(diff == starts[(j, o)] - original_start[key])\n",
    "                model.AddAbsEquality(dev, diff)\n",
    "                deviation_terms.append(dev)\n",
    "\n",
    "    # === Maschinenrestriktionen (inkl. fixierter Intervalle) ===\n",
    "    for m in machines:\n",
    "        machine_intervals = [interval for (j, o), (interval, mach) in intervals.items() if mach == m]\n",
    "        for fixed_start, fixed_end in fixed_ops.get(m, []):\n",
    "            start = math.floor(fixed_start)\n",
    "            end = math.ceil(fixed_end)\n",
    "            duration = end - start\n",
    "            if duration > 0:\n",
    "                fixed_interval = model.NewIntervalVar(start, duration, end, f\"fixed_{m}_{end}\")\n",
    "                machine_intervals.append(fixed_interval)\n",
    "        model.AddNoOverlap(machine_intervals)\n",
    "\n",
    "    # === Zielfunktion kombinieren ===\n",
    "    weighted_part = model.NewIntVar(0, horizon * len(weighted_terms), \"weighted_part\")\n",
    "    deviation_part = model.NewIntVar(0, horizon * len(deviation_terms), \"deviation_part\")\n",
    "    model.Add(weighted_part == sum(weighted_terms))\n",
    "    model.Add(deviation_part == sum(deviation_terms))\n",
    "\n",
    "    total_cost = model.NewIntVar(0, horizon * len(jobs) * 100, \"total_cost\")\n",
    "    model.Add(total_cost == r_scaled * weighted_part + (100 - r_scaled) * deviation_part)\n",
    "    model.Minimize(total_cost)\n",
    "\n",
    "    # === Solver-Einstellungen ===\n",
    "    solver = cp_model.CpSolver()\n",
    "    solver.parameters.log_search_progress = msg\n",
    "    solver.parameters.max_time_in_seconds = timeLimit\n",
    "    solver.parameters.relative_gap_limit = gapRel\n",
    "    status = solver.Solve(model)\n",
    "\n",
    "    # === Ergebnis extrahieren ===\n",
    "    records = []\n",
    "    if status in [cp_model.OPTIMAL, cp_model.FEASIBLE]:\n",
    "        for j, job in enumerate(jobs):\n",
    "            for o, (op_id, m, d) in enumerate(all_ops[j]):\n",
    "                st = solver.Value(starts[(j, o)])\n",
    "                ed = st + d\n",
    "                lateness_val = ed - deadline[job]\n",
    "                records.append({\n",
    "                    \"Job\": job,\n",
    "                    \"Operation\": op_id,\n",
    "                    \"Arrival\": arrival[job],\n",
    "                    \"Deadline\": deadline[job],\n",
    "                    \"Machine\": m,\n",
    "                    \"Start\": st,\n",
    "                    \"Processing Time\": d,\n",
    "                    \"End\": ed,\n",
    "                    \"Lateness\": lateness_val,\n",
    "                    \"Tardiness\": max(0, lateness_val),\n",
    "                    \"Earliness\": max(0, -lateness_val)\n",
    "                })\n",
    "\n",
    "        df_schedule = pd.DataFrame.from_records(records).sort_values([\"Start\", \"Job\", \"Operation\"]).reset_index(drop=True)\n",
    "    else:\n",
    "        print(f\"\\nSolver-Status         : {solver.StatusName(status)}\")\n",
    "        print(\"No feasible solution found!\")\n",
    "        df_schedule = pd.DataFrame()\n",
    "\n",
    "    # === Logging ===\n",
    "    print(f\"\\nSolver-Status         : {solver.StatusName(status)}\")\n",
    "    print(f\"Objective Value       : {solver.ObjectiveValue():.2f}\")\n",
    "    print(f\"Best Objective Bound  : {solver.BestObjectiveBound():.2f}\")\n",
    "    print(f\"Laufzeit              : {solver.WallTime():.2f} Sekunden\")\n",
    "    print(f\"Deviation terms       : {len(deviation_terms)}\")\n",
    "\n",
    "    return df_schedule\n"
   ],
   "id": "86b7b2a81ddf1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prefix_name = \"06_devpen\"\n",
    "first_start = 1\n",
    "last_planning_start = 7\n",
    "\n",
    "df_plan = df_plan_init\n",
    "df_execution = df_execution_init\n",
    "\n",
    "\n",
    "for day_numb in range(first_start, last_planning_start + 1):\n",
    "    day_start = day_length * day_numb\n",
    "    day_end = day_start + day_length\n",
    "    planning_end = day_start + horizon_days * day_length\n",
    "\n",
    "    # ------------------- I. Ankunfts- und Operationsvorbereitung -------------------\n",
    "    df_jssp_curr, df_times_curr = rp_proced.filter_jobs_by_arrival_window(df_times, df_jssp, day_start, planning_end)\n",
    "    df_jssp_curr = rp_proced.extend_with_undone_operations(df_jssp_curr, df_undone)\n",
    "    df_times_curr = rp_proced.update_times_after_operation_changes(df_times, df_jssp_curr)\n",
    "\n",
    "    # ------------------- II. Relevante laufende Operationen -------------------------\n",
    "    df_execution_important = rp_proced.get_operations_running_into_day(df_execution, day_start)\n",
    "\n",
    "    # ------------------- III. Rescheduling durchführen -------------------------------\n",
    "\n",
    "    starting_time = time.time()\n",
    "    df_plan = solve_cp_jssp_lateness_by_tardiness_and_earliness_with_devpen(df_jssp_curr, df_times_curr, df_execution_important,\n",
    "                                                                                 df_original_plan = df_plan, # prev. Plan\n",
    "                                                                                 w_t = 5,\n",
    "                                                                                 r = 0.70, # 70% Lateness, 30% Deviation\n",
    "                                                                                 reschedule_start = day_start,\n",
    "                                                                                 msg=False, timeLimit=max_time, gapRel= 0.05)\n",
    "\n",
    "    \n",
    "    solver_duration = time.time() - starting_time\n",
    "    print(f\"\\n  Scheduling-Dauer: {int(solver_duration // 60)} Minuten und {(solver_duration % 60):.2f} Sekunden.\")\n",
    "\n",
    "    df_plan.to_csv(get_schedule_filename(prefix_name, day=day_numb), index=False)\n",
    "\n",
    "    show.plot_gantt_machines(df_plan, title=f\"Gantt-Diagramm ab Tag {day_numb}\")\n",
    "    check.check_constraints(df_plan)\n",
    "\n",
    "    last_ops = df_plan.sort_values(['Job', 'Operation']).drop_duplicates('Job', keep='last')\n",
    "    print(show.count_column_grouped(last_ops, \"Lateness\", max_val = 180, steps= 60))\n",
    "\n",
    "    # ------------------- IV. Einen Tag simulieren -------------------------------------\n",
    "\n",
    "    simulation = ProductionDaySimulation(df_plan, vc=0.35)\n",
    "    df_execution, df_undone = simulation.run(start_time=day_start, end_time=day_end)\n",
    "    if not df_execution.empty:\n",
    "        show.plot_gantt_machines(df_execution, title=f\"Gantt-Diagramm für Simulationstag {day_numb}\", duration_column=\"Simulated Processing Time\")\n",
    "    else:\n",
    "        print(f\"Nothing executed on day {day_numb}\")\n"
   ],
   "id": "ac3d86a658a2380c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "notebook_duration = time.time() - start_notebook\n",
    "print(f\"Dauer: {int(notebook_duration // 60)} Minuten und {(notebook_duration % 60):.2f} Sekunden.\")"
   ],
   "id": "a8d047b382c03896"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
